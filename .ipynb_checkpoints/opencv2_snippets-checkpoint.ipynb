{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/cons.png')\n",
    "cv2.imshow('cons',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('images/person01_boxing_d1_uncomp.avi')\n",
    "while True:\n",
    "    suc, frame = cap.read()\n",
    "    if suc:\n",
    "        cv2.imshow('video', frame)\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4,480)\n",
    "# cap.set(4,100)\n",
    "while True:\n",
    "    suc, frame = cap.read()\n",
    "    if suc:\n",
    "        cv2.imshow('video', frame)\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/cons.png')\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('cons gray',gray_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/cons.png')\n",
    "blur_img = cv2.GaussianBlur(img, (7,7), 0)\n",
    "cv2.imshow('blur img',blur_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/store.jpg')\n",
    "canny_img = cv2.Canny(img, 200, 300)\n",
    "cv2.imshow('canny img',canny_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    canny_img = cv2.Canny(img, i*100, (i+1)*100)\n",
    "    cv2.imshow('canny img',canny_img)\n",
    "    cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/store.jpg')\n",
    "canny_img = cv2.Canny(img, 200, 300)\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "dil_img = cv2.dilate(canny_img, kernel, iterations = 3)\n",
    "cv2.imshow('canny img',dil_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/mahdi.jpg')\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "erod_img = cv2.erode(dil_img, kernel, iterations = 3)\n",
    "cv2.imshow('erod_img',erod_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/mahdi.jpg')\n",
    "kernel = np.ones((7,7), np.uint8)\n",
    "erod_img = cv2.dilate(img, kernel)\n",
    "cv2.imshow('erod_img',erod_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/mahdi.jpg')\n",
    "resize_img = cv2.resize(img, (640, 480) )\n",
    "cv2.imshow(f'original {img.shape[0]},{img.shape[1]} to {resize_img.shape[0]}, {resize_img.shape[1]}',resize_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/mahdi.jpg')\n",
    "rec_img = cv2.rectangle(img, (10,10), (500,100),(12,53,32),cv2.FILLED)\n",
    "cv2.imshow('rec_img',rec_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/mahdi.jpg')\n",
    "text_img = cv2.putText(img,\"this is mahdi\", (0, 20), cv2.FONT_HERSHEY_COMPLEX,1, (0,0,0), 3)\n",
    "cv2.imshow('text_img',text_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/paper.jpeg')\n",
    "img_resize = cv2.resize(img, (640, 480))\n",
    "width, height = 640, 480\n",
    "pst1 = np.float32([[40, 154], [330, 106], [220 , 390], [580, 290]])\n",
    "pst2 = np.float32([[0,0], [width,0], [0, height], [width, height]])\n",
    "matrix = cv2.getPerspectiveTransform(pst1, pst2)\n",
    "img_trans = cv2.warpPerspective(img_resize, matrix, (width, height))\n",
    "hor_img = np.hstack((img_resize, img_trans))\n",
    "cv2.imshow('img_trans',hor_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img = cv2.imread('images/erase_image.jpg')\n",
    "hsv_value = {'hue_min' : 50, 'sat_min': 63, 'val_min' : 0,\n",
    "            'hue_max' : 76, 'sat_max': 255, 'val_max' : 236}\n",
    "def hue_caller(index,value, img):\n",
    "    global hsv_value\n",
    "    hsv_value[index] = value\n",
    "#     print(hsv_value)\n",
    "    lower = np.array([hsv_value['hue_min'], hsv_value['sat_min'], hsv_value['val_min']])\n",
    "    upper = np.array([hsv_value['hue_max'], hsv_value['sat_max'], hsv_value['val_max']])\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "#     cv2.imshow('mask image', mask)\n",
    "    res_img = cv2.bitwise_and(org_img, org_img, mask = mask)\n",
    "    cv2.imshow('result image',res_img)\n",
    "#     stack_img = np.vstack((org_img, res_img))\n",
    "#     cv2.imshow('complete images', stack_img)\n",
    "\n",
    "hsv_img = cv2.cvtColor(org_img, cv2.COLOR_BGR2HSV)\n",
    "cv2.namedWindow('TrackBars')\n",
    "cv2.resizeWindow('TrackBars', 480, 120)\n",
    "cv2.createTrackbar('Hue Min', 'TrackBars', hsv_value['hue_min'], 360, lambda x: hue_caller('hue_min',x, hsv_img))\n",
    "cv2.createTrackbar('Hue Max', 'TrackBars', hsv_value['hue_max'], 360, lambda x: hue_caller('hue_max',x, hsv_img))\n",
    "cv2.createTrackbar('Saturation Min', 'TrackBars', hsv_value['sat_min'], 360, lambda x: hue_caller('sat_min',x, hsv_img))\n",
    "cv2.createTrackbar('Saturation Max', 'TrackBars', hsv_value['sat_max'], 360, lambda x: hue_caller('sat_max',x, hsv_img))\n",
    "cv2.createTrackbar('Value Min', 'TrackBars', hsv_value['val_min'], 360, lambda x: hue_caller('val_min',x, hsv_img))\n",
    "cv2.createTrackbar('Value Max', 'TrackBars', hsv_value['val_max'], 360, lambda x: hue_caller('val_max',x, hsv_img))\n",
    "\n",
    "\n",
    "# cv2.imshow('colored shapes', img)\n",
    "# cv2.imshow('hsv image', hsv_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = {'thresh_min':30, 'thresh_max':50}\n",
    "def get_contours(img):\n",
    "    contours, hierchy = cv2.findContours(img,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "#     print(contours)\n",
    "    blnk_img = np.zeros_like(img)\n",
    "    for cnt in contours:\n",
    "        arc_len = cv2.arcLength(cnt, True)\n",
    "        obj_poly = cv2.approxPolyDP(cnt,0.02*arc_len,True)\n",
    "        obj_cor = len(obj_poly)\n",
    "        if obj_cor==4 :\n",
    "            obj_shape='square'\n",
    "        elif obj_cor==3:\n",
    "            obj_shape='Tri'\n",
    "        else:\n",
    "            obj_shape='circle'\n",
    "        cv2.putText(blnk_img, f'{arc_len:.2f} , {obj_shape}' , tuple(cnt[0][0]), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255) )\n",
    "        cv2.drawContours(blnk_img, cnt,-1, (255, 255, 255))\n",
    "        cv2.imshow('conours', blnk_img)\n",
    "\n",
    "def track_call(index, v):\n",
    "    global thresh\n",
    "#     print(index, v)\n",
    "    thresh[index] = v\n",
    "    edge_img = cv2.Canny(gray_img, thresh['thresh_min'], thresh['thresh_max'])\n",
    "    get_contours(edge_img)\n",
    "    cv2.imshow('edge_img', edge_img)\n",
    "    \n",
    "org_img = cv2.imread('images/shapes.jpg')\n",
    "gray_img = cv2.cvtColor(org_img, cv2.COLOR_BGR2GRAY)\n",
    "edge_img = cv2.Canny(gray_img, 30, 50)\n",
    "cv2.imshow('edge_img', edge_img)\n",
    "cv2.createTrackbar('thresh1', 'edge_img', thresh['thresh_min'], 100, lambda x: track_call('thresh_min', x))\n",
    "cv2.createTrackbar('thresh2', 'edge_img', thresh['thresh_max'], 100, lambda x: track_call('thresh_max', x))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4,480)\n",
    "# cap.set(4,100)\n",
    "draw_hsv_value= {\n",
    "    'hue_min': 37,\n",
    "    'hue_max': 74,\n",
    "    'sat_min': 32,\n",
    "    'sat_max': 235,\n",
    "    'val_min': 158,\n",
    "    'val_max': 222\n",
    "}\n",
    "\n",
    "erase_hsv_value= {\n",
    "    'hue_min': 97,\n",
    "    'hue_max': 128,\n",
    "    'sat_min': 8,\n",
    "    'sat_max': 22,\n",
    "    'val_min': 238,\n",
    "    'val_max': 360\n",
    "}\n",
    "\n",
    "draw_lower = np.array([draw_hsv_value['hue_min'], draw_hsv_value['sat_min'], draw_hsv_value['val_min']])\n",
    "draw_upper = np.array([draw_hsv_value['hue_max'], draw_hsv_value['sat_max'], draw_hsv_value['val_max']])\n",
    "\n",
    "erase_lower = np.array([erase_hsv_value['hue_min'], erase_hsv_value['sat_min'], erase_hsv_value['val_min']])\n",
    "erase_upper = np.array([erase_hsv_value['hue_max'], erase_hsv_value['sat_max'], erase_hsv_value['val_max']])\n",
    "\n",
    "def drawer(img):\n",
    "    global paint\n",
    "    draw_mask = cv2.inRange(img, draw_lower, draw_upper)\n",
    "    paint = draw_mask|paint\n",
    "    \n",
    "    erase_mask = cv2.inRange(img, erase_lower, erase_upper)\n",
    "    erase_mask = cv2.bitwise_not(erase_mask)\n",
    "    paint = cv2.bitwise_and(erase_mask ,paint)\n",
    "    \n",
    "    green_page = np.zeros_like(frame_resize)\n",
    "    green_page[:,:,1]= 255\n",
    "    paint_area = cv2.bitwise_and(green_page, green_page, mask = paint)\n",
    "    res_img = cv2.bitwise_or(frame_resize, paint_area)\n",
    "    cv2.imshow('paint image',res_img)\n",
    "\n",
    "\n",
    "\n",
    "paint = np.zeros((640, 480), dtype= np.uint8)\n",
    "\n",
    "while True:\n",
    "    suc, frame = cap.read()\n",
    "    if suc:\n",
    "#         cv2.imshow('video', frame)\n",
    "        frame_resize = cv2.resize(frame,(480, 640) )\n",
    "        hsv_img = cv2.cvtColor(frame_resize, cv2.COLOR_BGR2HSV)\n",
    "        drawer(hsv_img)\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## should work more and fix buges\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('images/paper.jpeg')\n",
    "img = cv2.resize(img, (640, 480))\n",
    "thresh= {'min': 300, 'max':400}\n",
    "\n",
    "def wrap_presp(img, cords):\n",
    "    width, height = img.shape[:2]\n",
    "    w, h = np.max(cords[:,0]) + np.min(cords[:,0]), np.max(cords[:,1]) + np.min(cords[:,1])\n",
    "    cx , cy = w/2, h/2\n",
    "    maskx= cords[:,0] <cx\n",
    "    masky = cords[:,1] <cy\n",
    "    cords_ = list([\n",
    "        cords[maskx&masky,:] if np.ndim(cords[maskx&masky,:])==1 else cords[maskx&masky,:][0],\n",
    "        cords[maskx&~masky,:] if np.ndim(cords[maskx&~masky,:])==1 else cords[maskx&~masky,:][0],\n",
    "        cords[~maskx&masky,:] if np.ndim(cords[~maskx&masky,:])==1 else  cords[~maskx&masky,:][0],\n",
    "        cords[~maskx&~masky,:] if np.ndim(cords[~maskx&~masky,:])==1 else cords[~maskx&~masky,:][0],\n",
    "    ])\n",
    "#     print(cords_)\n",
    "    cords_ = np.array(cords_, dtype=np.float32)\n",
    "    pst1 = cords_\n",
    "    pst2 = np.float32([[0,0], [width,0], [0, height], [width, height]])\n",
    "    matrix = cv2.getPerspectiveTransform(pst1, pst2)\n",
    "    img_trans = cv2.warpPerspective(img, matrix, (width, height))\n",
    "    return img_trans\n",
    "\n",
    "def contours_call(img):\n",
    "    contoures, hiarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    max_len = 0\n",
    "    max_len_ind = 0\n",
    "    for i, cnt in enumerate(contoures):\n",
    "        arc_len = cv2.contourArea(cnt)\n",
    "        if arc_len > max_len:\n",
    "            max_len = arc_len\n",
    "            max_len_ind = i\n",
    "    obj_poly = cv2.approxPolyDP(contoures[max_len_ind],0.02*max_len,True)\n",
    "    return obj_poly\n",
    "\n",
    "def edge_call(index, value):\n",
    "    thresh[index] = value\n",
    "    edge_img = cv2.Canny(gray_img, thresh['min'], thresh['max'])\n",
    "#     cv2.imshow('edges', dil_img)\n",
    "    return dil_img\n",
    "def prep(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edge_img = cv2.Canny(gray_img, thresh['min'], thresh['max'])\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dil_img = cv2.dilate(edge_img, kernel, iterations = 7)\n",
    "    return edge_img\n",
    "\n",
    "edge_img= prep(img)\n",
    "cv2.imshow('edges', edge_img)\n",
    "cords = contours_call(edge_img)\n",
    "cords = cords[:,0].astype(np.float32)\n",
    "# print(cords)\n",
    "paper = wrap_presp(img, cords)\n",
    "cv2.imshow('paper', paper)\n",
    "# cv2.imshow('edges', edge_img)\n",
    "# cv2.createTrackbar('thresh1', 'edges', thresh['min'], 400, lambda x: edge_call('min', x))\n",
    "# cv2.createTrackbar('thresh2', 'edges', thresh['max'], 400, lambda x: edge_call('max', x))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contours base online paper scan\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4,480)\n",
    "# cap.set(4,100)\n",
    "while True:\n",
    "    suc, frame = cap.read()\n",
    "    if suc:\n",
    "        try:\n",
    "            edge_img= prep(frame)\n",
    "            cv2.imshow('edges', edge_img)\n",
    "            cords = contours_call(edge_img)\n",
    "            # print(cords)\n",
    "            cords = cords[:,0].astype(np.float32)\n",
    "            cords_ = np.array([cords[3], cords[2], cords[0], cords[1]])\n",
    "            paper = wrap_presp(img, cords_)\n",
    "            cv2.imshow('paper', paper)\n",
    "        except:\n",
    "            pass\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 3],\n",
       "       [1, 4],\n",
       "       [5, 1],\n",
       "       [5, 5]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,1], [1,3], [1,4], [5,1], [5,5]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 2.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, h = np.max(a[:,0]) - np.min(a[:,0]), np.max(a[:,1]) - np.min(a[:,1])\n",
    "cx , cy = w/2, h/2\n",
    "cx , cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True, False, False]),\n",
       " array([ True, False, False,  True, False]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskx= a[:,0] <cx\n",
    "masky = a[:,1] <cy\n",
    "maskx , masky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[maskx&masky, :][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~maskx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
